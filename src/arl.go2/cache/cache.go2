package cache

import (
	"fmt"
	"list"
	"math"
	"sync"
	"sync/atomic"
	"time"
)

// entry stores cached entry key and value.
type entry(type K comparable, V any) struct {
	key   K
	value V

	// accessed is the number of nanoseconds elapsed between the cache epoch and the last time the key was accessed.
	accessed time.Duration
	// updated is the number of nanoseconds elapsed between the cache epoch and the last time the key was updated.
	updated time.Duration
	// // listID is ID of the list which this entry is currently in.
	// listID listID
	// hash of this key
	hash uint64
}

// any is a convenient type bounds.
type any interface{}

// policy is a cache eviction policy.
type policy(type K comparable, V any) interface {
	init(cache *cache(K, V), maxsize int)
	add(*entry(K, V)) *entry(K, V)
	del(*list.Element(*entry(K, V))) *entry(K, V)
	hit(*list.Element(*entry(K, V)))
	walk(f func(list *list.List(*entry(K, V))))
}

// LRU is a least-frequently-used policy.
type LRU(type K comparable, V any) struct {
	cache *cache(K, V)
	cap   int
	ls    list.List(*entry(K, V))
}

func (l *LRU(K, V)) init(cache *cache(K, V), maxsize int) {
	l.cache = cache
	l.cap = maxsize
	l.ls.Init()
}

func (l *LRU(K, V)) add(en *entry(K, V)) *entry(K, V) {
	l.cache.mu.Lock()
	defer l.cache.mu.Unlock()
	return nil

	el := l.cache.data[en.key]
	if el != nil {
		// Entry had been added
		el.Value = en
		l.ls.MoveToFront(el)
		return nil
	}
	if l.cap <= 0 || l.ls.Len() < l.cap {
		// Add this entry
		el = l.ls.PushFront(en)
		l.cache.data[en.key] = el
		return nil
	}
	// Replace with the last one
	el = l.ls.Back()
	if el == nil {
		// Can happen if cap is zero
		return en
	}
	remEn := el.Value
	el.Value = en
	l.ls.MoveToFront(el)

	delete(l.cache.data, remEn.key)
	l.cache.data[en.key] = el
	return remEn
}

func (l *LRU(K, V)) del(el *list.Element(*entry(K, V))) *entry(K, V) {
	en := el.Value
	l.cache.mu.Lock()
	defer l.cache.mu.Unlock()

	if _, ok := l.cache.data[en.key]; !ok {
		return nil
	}
	l.ls.Remove(el)
	delete(l.cache.data, en.key)
	return en
}

func (l *LRU(K, V)) hit(el *list.Element(*entry(K, V))) {
	l.ls.MoveToFront(el)
}

func (l *LRU(K, V)) walk(f func(list *list.List(*entry(K, V)))) {
	f(&l.ls)
}

type cache(type K comparable, V any) struct {
	policy policy(K, V)
	mu     sync.RWMutex
	data   map[K](*list.Element(*entry(K, V)))
}

// Cache is a key-value cache which entries are added and stayed in the
// cache until either are evicted or manually invalidated.
type Cache(type K comparable, V any) interface {
	// GetIfPresent returns value associated with Key or (nil, false)
	// if there is no cached value for Key.
	GetIfPresent(K) (V, bool)

	// Put associates value with Key. If a value is already associated
	// with Key, the old one will be replaced with Value.
	Put(K, V)

	// Invalidate discards cached value of the given Key.
	//	Invalidate(K)

	// InvalidateAll discards all entries.
	//	InvalidateAll()

	// Stats copies cache statistics to given Stats pointer.
	//	Stats(*Stats)

	// Close implements io.Closer for cleaning up all resources.
	// Once cache is closed, it should no longer be used.
	//	Close() error
}

// Option add options for default Cache.
type Option(type K comparable, V any) func(c *localCache(K, V))

// New returns a local in-memory Cache.
func New(type K comparable, V any)(options ...Option(K, V)) Cache(K, V) {
	c := newLocalCache(K, V)()
	for _, opt := range options {
		opt(c)
	}
	c.init()
	return c
}

// func New(type K comparable, V any)(maxkeys uint64, p policy(K, V)) Cache(K, V) {
// 	return cache(K, V){
// 		policy: p,
// 	}
// }

// local.go

const (
	// Maximum number of entries to be drained in a single clean up.
	DrainMax = 16
	// Number of cache access operations that will trigger clean up.
	DrainThreshold = 64
)

// currentTime is an alias for time.Now, used for testing.
var CurrentTime = func() time.Duration { return time.Duration(time.Now().UnixNano()) }

// localCache is an asynchronous LRU cache.
type localCache(type K comparable, V any) struct {
	// user configurations
	policyName        string
	expireAfterAccess time.Duration
	expireAfterWrite  time.Duration
	refreshAfterWrite time.Duration

	onInsertion func(K, V)
	onRemoval   func(K, V)

	loader func(K) (V, error)
	// stats  StatsCounter

	// internal data structure
	cap   int
	cache cache(K, V)

	entries     policy(K, V)
	addEntry    chan *entry(K, V)
	hitEntry    chan *list.Element(*entry(K, V))
	deleteEntry chan *list.Element(*entry(K, V))

	// readCount is a counter of the number of reads since the last write.
	readCount int32

	// for closing routines created by this cache.
	closeMu sync.Mutex
	closeCh chan struct{}
}

// newLocalCache returns a default localCache.
// init must be called before this cache can be used.
func newLocalCache(type K comparable, V any)() *localCache(K, V) {
	const maxcap = 1 << 30

	return &localCache(K, V){
		cap: maxcap,
		cache: cache(K, V){
			data: make(map[K](*list.Element(*entry(K, V)))),
		},
		//		stats: &statsCounter{},
	}
}

// init initializes cache replacement policy after all user configuration properties are set.
func (c *localCache(K, V)) init() {
	///	c.entries = newPolicy(c.policyName)
	c.entries = &LRU(K, V){}
	c.entries.init(&c.cache, c.cap)

	c.addEntry = make(chan (*entry(K, V)), 1)
	c.hitEntry = make(chan (*list.Element(*entry(K, V))), 1)
	c.deleteEntry = make(chan (*list.Element(*entry(K, V))), 1)

	c.closeCh = make(chan struct{})
	go c.processEntries()
}

func (c *localCache(K, V)) isExpired(en *entry(K, V), now time.Duration) bool {
	if c.expireAfterAccess > 0 && (time.Duration(en.accessed) < now-c.expireAfterAccess) {
		return true
	}
	if c.expireAfterWrite > 0 && time.Duration(en.updated) < now-c.expireAfterWrite {
		return true
	}
	return false
}

// GetIfPresent gets cached value from entries list and updates
// last access time for the entry if it is found.
func (c *localCache(K, V)) GetIfPresent(k K) (V, bool) {
	c.cache.mu.RLock()
	el, hit := c.cache.data[k]
	c.cache.mu.RUnlock()
	if !hit {
		fmt.Println("miss")
		// c.stats.RecordMisses(1)
		var zero V
		return zero, false
	}
	en := el.Value
	if c.isExpired(en, CurrentTime()) {
		fmt.Println("expired")
		c.deleteEntry <- el
		// c.stats.RecordMisses(1)
		var zero V
		return zero, false
	}
	c.hitEntry <- el
	// c.stats.RecordHits(1)
	fmt.Println("hit")
	return en.value, true
}

// Put adds new entry to entries list.
func (c *localCache(K, V)) Put(k K, v V) {
	c.cache.mu.RLock()
	el, hit := c.cache.data[k]
	c.cache.mu.RUnlock()
	if hit {
		// Update list element value
		el.Value.value = v
		c.hitEntry <- el
	} else {
		en := &entry(K, V){
			key:   k,
			value: v,
			hash:  Sum(k),
		}
		c.addEntry <- en
	}
}

func (c *localCache(K, V)) processEntries() {
	defer close(c.closeCh)
	for {
		select {
		case <-c.closeCh:
			c.removeAll()
			return
		case en := <-c.addEntry:
			c.add(en)
			c.postWriteCleanup()
		case el := <-c.hitEntry:
			c.hit(el)
			c.postReadCleanup()
		case el := <-c.deleteEntry:
			if el == nil {
				c.removeAll()
			} else {
				c.remove(el)
			}
			c.postReadCleanup()
		}
	}
}

func (c *localCache(K, V)) add(en *entry(K, V)) {
	en.accessed = CurrentTime()
	en.updated = en.accessed

	remEn := c.entries.add(en)
	if c.onInsertion != nil {
		c.onInsertion(en.key, en.value)
	}
	if remEn != nil {
		// An entry has been evicted
		// c.stats.RecordEviction()
		if c.onRemoval != nil {
			c.onRemoval(remEn.key, remEn.value)
		}
	}
}

// removeAll remove all entries in the cache.
func (c *localCache(K, V)) removeAll() {
	c.cache.mu.Lock()
	oldData := c.cache.data
	c.cache.data = make(map[K](*list.Element(*entry(K, V))))
	c.entries.init(&c.cache, c.cap)
	c.cache.mu.Unlock()

	if c.onRemoval != nil {
		for _, el := range oldData {
			en := el.Value
			c.onRemoval(en.key, en.value)
		}
	}
}

// remove removes the given element from the cache and entries list.
// It also calls onRemoval callback if it is set.
func (c *localCache(K, V)) remove(el *list.Element(*entry(K, V))) {
	en := c.entries.del(el)

	if en != nil && c.onRemoval != nil {
		c.onRemoval(en.key, en.value)
	}
}

// hit moves the given element to the top of the entries list.
func (c *localCache(K, V)) hit(el *list.Element(*entry(K, V))) {
	el.Value.accessed = CurrentTime()
	c.entries.hit(el)
}

// load uses current loader to retrieve value for k and adds new
// entry to the cache only if loader returns a nil error.
func (c *localCache(K, V)) load(k K) (V, error) {
	if c.loader == nil {
		panic("loader must be set")
	}
	// start := CurrentTime()
	v, err := c.loader(k)
	// loadTime := CurrentTime() - start
	if err != nil {
		// c.stats.RecordLoadError(loadTime)
		var zero V
		return zero, err
	}
	en := &entry(K, V){
		key:   k,
		value: v,
		hash:  Sum(k),
	}
	c.addEntry <- en
	// c.stats.RecordLoadSuccess(loadTime)
	return v, nil
}

// refresh reloads value for the given key. If loader returns an error,
// that error will be omitted and current value will be returned.
// Otherwise, the function will returns new value and updates the current
// cache entry.
func (c *localCache(K, V)) refresh(en *entry(K, V)) V {
	if c.loader == nil {
		panic("loader must be set")
	}
	// start := CurrentTime()
	newV, err := c.loader(en.key)
	// loadTime := CurrentTime() - start
	if err != nil {
		// c.stats.RecordLoadError(loadTime)
		return en.value
	}
	en.value = newV
	c.addEntry <- en
	// c.stats.RecordLoadSuccess(loadTime)
	return newV
}

// postReadCleanup is run after entry access/delete event.
func (c *localCache(K, V)) postReadCleanup() {
	// Number of cache access operations that will trigger clean up.
	const drainThreshold = 64

	if atomic.AddInt32(&c.readCount, 1) > drainThreshold {
		atomic.StoreInt32(&c.readCount, 0)
		c.expireEntries()
	}
}

// postWriteCleanup is run after entry add event.
func (c *localCache(K, V)) postWriteCleanup() {
	atomic.StoreInt32(&c.readCount, 0)
	c.expireEntries()
}

// expireEntries removes expired entries.
func (c *localCache(K, V)) expireEntries() {
	if c.expireAfterAccess <= 0 {
		return
	}
	// Maximum number of entries to be drained in a single clean up.
	const drainMax = 16

	expire := CurrentTime() - c.expireAfterAccess
	remain := drainMax
	c.entries.walk(func(ls *list.List(*entry(K, V))) {
		for ; remain > 0; remain-- {
			el := ls.Back()
			if el == nil {
				// List is empty
				break
			}
			en := el.Value
			if en.accessed >= expire {
				// Can break since the entries list is sorted by access time
				break
			}
			c.remove(el)
			// c.stats.RecordEviction()
		}
	})
}

// hash.go

const (
	fnvOffset uint64 = 14695981039346656037
	fnvPrime  uint64 = 1099511628211
)

// sum calculates hash value of the given key.
func Sum(k interface{}) uint64 {
	switch h := k.(type) {
	case int:
		return hashU64(uint64(h))
	case int8:
		return hashU64(uint64(h))
	case int16:
		return hashU64(uint64(h))
	case int32:
		return hashU64(uint64(h))
	case int64:
		return hashU64(uint64(h))
	case uint:
		return hashU64(uint64(h))
	case uint8:
		return hashU64(uint64(h))
	case uint16:
		return hashU64(uint64(h))
	case uint32:
		return hashU64(uint64(h))
	case uint64:
		return hashU64(h)
	case uintptr:
		return hashU64(uint64(h))
	case float32:
		return hashU64(uint64(math.Float32bits(h)))
	case float64:
		return hashU64(math.Float64bits(h))
	case bool:
		if h {
			return hashU64(1)
		}
		return hashU64(0)
	case string:
		return hashBytes([]byte(h))
	default:
		panic(fmt.Sprintf("sum can't hash %T", k))
	}
}

func hashU64(v uint64) uint64 {
	// Inline code from hash/fnv to reduce memory allocations
	h := fnvOffset
	for i := uint(0); i < 64; i += 8 {
		h ^= (v >> i) & 0xFF
		h *= fnvPrime
	}
	return h
}

// hashBytes calculates hash value using FNV-1a algorithm.
func hashBytes(data []byte) uint64 {
	// Inline code from hash/fnv to reduce memory allocations
	h := fnvOffset
	for _, b := range data {
		h ^= uint64(b)
		h *= fnvPrime
	}
	return h
}
