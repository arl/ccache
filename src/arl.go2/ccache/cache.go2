package ccache

import (
	"hash/maphash"
	"sync"
)

type Any interface{}

type Cache(type K comparable, V Any) interface {
	Get(K) (V, bool)
	Set(K, V)
	Del(K)

	Metrics(*Metrics)
}

func New(type K comparable, V Any)(opts ...option(K, V))  Cache(K, V) {
	return newCache(K, V)(opts...)
}

type partition(type K comparable, V Any) struct {
	sync.RWMutex
	m map[K]V
	// TODO: cache line padding
}

const PartCount = 64

type option (type K comparable, V Any) func (*cache(K, V))

func WithMaxCapacity(type K comparable, V Any)(cap int) option(K,V) {
	return func(c*cache(K, V)) {
		c.cap = cap
	}
}

func WithPolicy(type K comparable, V Any)(p Policy(K)) option(K,V) {
	return func(c*cache(K, V)) {
		c.policy = p
	}
}

type cache(type K comparable, V Any) struct {
	m      [PartCount]partition(K, V)
	cap int
	policy Policy(K)

	metrics Metrics

	hash func(*maphash.Hash, interface{}) uint64
	mh   *maphash.Hash
}
// (cap int, policy Policy(K)
func newCache(type K comparable, V Any)(opts ...option(K, V)) *cache(K, V) {
	const defaultCapacity = 32*1024

	c := &cache(K, V){
		cap: defaultCapacity,
		policy: NewFIFO(K)(defaultCapacity),
		hash:   hashFunction(K)(),
		mh:     &maphash.Hash{},
	}

	for _, opt := range opts {
		_ = opt
	}

	// c.mh.SetSeed()

	// Allocate partitions
	for i := 0; i < PartCount; i++ {
		part := partition(K, V){m: make(map[K]V, c.cap/64)}
		c.m[i] = part
	}

	return c
}

/*
cache should be concurrent:
so multiple goroutine can get keys as long as nobody is writing
see, from https://software.intel.com/content/www/us/en/develop/blogs/debugging-performance-issues-in-go-programs.html
*/

func (c *cache(K, V)) Get(k K) (V, bool) {
	idx := c.hash(c.mh, k) % PartCount
	part := &c.m[idx]

	part.RLock()
	v, ok := part.m[k]
	part.RUnlock()

	if !ok {
		c.metrics.IncrMisses()
		return v, false
	}

	c.metrics.IncrHits()
	return v, ok
}

func (c *cache(K, V)) Set(k K, v V) {
	idx := c.hash(c.mh, k) % PartCount
	part := &c.m[idx]

	part.Lock()
	part.m[k] = v
	part.Unlock()
}

func (c *cache(K, V)) Del(k K) {
	idx := c.hash(c.mh, k) % PartCount
	part := &c.m[idx]

	part.Lock()
	delete(part.m, k)
	part.Unlock()
}

func (c *cache(K, V)) Metrics(m *Metrics) {
	c.metrics.Snapshot(m)
}

// func (c *cache(K, V)) Close() error {
// 	close(c.quit)
// 	return nil
// }
